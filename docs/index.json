[{"content":"Description The Ticket Suggestion System is an AI-driven solution designed to assist IT support agents in resolving new tickets efficiently by leveraging Natural Language Processing (NLP) and semantic search techniques. Built using Python, FAISS, and Streamlit, the system analyzes incoming support tickets and matches them with previously resolved cases based on cosine similarity and semantic embeddings.\nThe NLP-powered backend ensures precise analysis of ticket descriptions, while the FAISS index enables fast and scalable similarity searches across large datasets of historical tickets. The Streamlit-based frontend provides an intuitive and user-friendly interface, allowing support agents to input ticket details and instantly receive relevant suggestions for solutions.\nBy reducing repetitive manual searches and offering AI-driven recommendations, this system significantly enhances response time, accuracy, and workflow efficiency for IT support teams.\nThis project highlights the seamless integration of AI, NLP, and scalable search algorithms to optimize IT support workflows and deliver actionable insights in real-time. ","permalink":"https://github.com/siri-sha-kondeti/Sirisha_Main_portfolio.git/projects/ticket-suggestion-system/","summary":"\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eThe Ticket Suggestion System is an AI-driven solution designed to assist IT support agents in resolving new tickets efficiently by leveraging Natural Language Processing (NLP) and semantic search techniques. Built using Python, FAISS, and Streamlit, the system analyzes incoming support tickets and matches them with previously resolved cases based on cosine similarity and semantic embeddings.\u003c/p\u003e\n\u003cp\u003eThe NLP-powered backend ensures precise analysis of ticket descriptions, while the FAISS index enables fast and scalable similarity searches across large datasets of historical tickets. The Streamlit-based frontend provides an intuitive and user-friendly interface, allowing support agents to input ticket details and instantly receive relevant suggestions for solutions.\u003c/p\u003e","title":"AI-Powered Ticket Suggestion System"},{"content":"Description Enable visually impaired individuals to navigate effortlessly with voice-oriented navigation systems, Used advanced technologies that recognize and speak in real-time to guide them audibly. Created a simple interface using HTML, CSS, and Javascript and connected them with backend system FLASK, RESTAPI, and PostgreSQL. Used wake word detection, Speech Recognition and gTTS (Text-to-Speech) engines and easy-to-use APIs from Google. These solutions make it easier for them to get around without needing extra help, so they can feel more confident exploring their surroundings.\n","permalink":"https://github.com/siri-sha-kondeti/Sirisha_Main_portfolio.git/projects/voice-oriented-navigation/","summary":"\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eEnable visually impaired individuals to navigate effortlessly with voice-oriented navigation systems, Used advanced\ntechnologies that recognize and speak in real-time to guide them audibly. Created a simple interface using HTML,\nCSS, and Javascript and connected them with backend system FLASK, RESTAPI, and PostgreSQL. Used wake\nword detection, Speech Recognition and gTTS (Text-to-Speech) engines and easy-to-use APIs from Google.\nThese solutions make it easier for them to get around without needing extra help, so they can feel more confident\nexploring their surroundings.\u003c/p\u003e","title":"Developed Software Application for voice-oriented navigation for blind individuals (Bachelor Thesis)"},{"content":"Description This project focuses on developing an advanced Face Detection and 3D Reconstruction system using landmark points to achieve precise facial recognition and lifelike 3D facial representations. Leveraging Computer Vision and Machine Learning techniques, the system accurately detects faces in images and video streams, maps key facial features, and reconstructs them in three dimensions.\nThe face detection module ensures reliable identification of faces even in complex or dynamic environments. The landmark detection module precisely maps facial features, enabling detailed analysis of facial geometry. The 3D reconstruction module utilizes these landmark points to create accurate 3D representations of detected faces.\nThis system can be applied in various domains, including biometric authentication, virtual avatar creation, medical imaging, security systems, and entertainment technologies. The integration of accurate face detection with precise 3D reconstruction makes this project a valuable contribution to the evolving landscape of facial recognition and analysis.\nTechnologies Used Programming Languages: Python Libraries and Frameworks: OpenCV, PyTorch Techniques: Landmark Point Detection, 3D Reconstruction Algorithms, Machine Learning Models Applications: Image and Video Processing, Real-time Facial Analysis This project showcases the fusion of AI-driven facial recognition with 3D modeling techniques, offering a robust and scalable solution for modern facial analysis systems.\n","permalink":"https://github.com/siri-sha-kondeti/Sirisha_Main_portfolio.git/projects/face-landmarks-detection/","summary":"\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eThis project focuses on developing an advanced Face Detection and 3D Reconstruction system using landmark points to achieve precise facial recognition and lifelike 3D facial representations. Leveraging Computer Vision and Machine Learning techniques, the system accurately detects faces in images and video streams, maps key facial features, and reconstructs them in three dimensions.\u003c/p\u003e\n\u003cp\u003eThe face detection module ensures reliable identification of faces even in complex or dynamic environments. The landmark detection module precisely maps facial features, enabling detailed analysis of facial geometry. The 3D reconstruction module utilizes these landmark points to create accurate 3D representations of detected faces.\u003c/p\u003e","title":"Face Detection and 3D Reconstruction Using Landmark Points"},{"content":"Description Developed an advanced crop yield prediction application for a regional agricultural cooperative, enhancing farming decisions and yield forecasts with remarkable precision. Utilized a robust tech stack including Crop Disease detection, CNN, HTML, CSS, Javascript, Python, FAST API, sci-kit-learn, PyTorch, Numpy, and Pandas for effective data analysis and predictive modeling. Integrated cutting-edge data preprocessing techniques such as statistical analysis, feature engineering, and data normalization to refine model accuracy. Historical weather data were incorporated using OpenWeatherMap API and also used Leaflet maps for visualization and real-time projection.\nOpenWeatherMap API Crop Disease detection Crop Disease detection Looking ahead, I\u0026rsquo;m excited about the next phase of this project, which involves integrating Artificial Intelligence (AI) to diagnose plant diseases. This feature will enable early detection and more effective management of crop health, potentially saving crops from significant damage.\nAdditionally, I\u0026rsquo;m working on incorporating Machine Learning (ML) models to predict the impact of climate and soil moisture levels on crop yields. These tools provide real-time insights and actionable advice to optimize farming conditions and improve crop productivity.\n","permalink":"https://github.com/siri-sha-kondeti/Sirisha_Main_portfolio.git/projects/crop-yield-prediction-application/","summary":"\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eDeveloped an advanced crop yield prediction application for a regional\nagricultural cooperative, enhancing farming decisions and yield forecasts with remarkable precision. Utilized a\nrobust tech stack including Crop Disease detection, CNN, HTML, CSS, Javascript, Python, FAST\nAPI, sci-kit-learn, PyTorch, Numpy, and Pandas for effective data analysis and predictive modeling.\nIntegrated cutting-edge data preprocessing techniques such as statistical analysis, feature engineering, and data\nnormalization to refine model accuracy. Historical weather data were incorporated using OpenWeatherMap API\nand also used Leaflet maps for visualization and real-time projection.\u003c/p\u003e","title":"Crop Yield Prediction Application"},{"content":"Description The Smart Assistant is an AI-driven tool designed to optimize workflow efficiency and enhance productivity across various professional environments. Developed using Python, Natural Language Processing (NLP), Flask, and web technologies like HTML, CSS, and JavaScript, this assistant provides real-time assistance for a wide range of tasks with a user-friendly interface that ensures accessibility for users at all technical levels.\nAt its core, the assistant leverages advanced NLP techniques to understand and respond to complex queries with high accuracy. The system integrates seamlessly with existing workflows, adding intelligent functionality without requiring significant changes to established processes. Additionally, it offers customization features that allow users to tailor the assistant’s capabilities to their specific needs, making it highly adaptable to different operational scenarios.\nBy combining AI-driven insights, an intuitive UI, and scalable backend architecture, this project serves as a powerful tool for enhancing productivity, streamlining tasks, and improving decision-making processes in professional settings.\nResponse from Assistant ","permalink":"https://github.com/siri-sha-kondeti/Sirisha_Main_portfolio.git/projects/smart-assistant/","summary":"\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eThe Smart Assistant is an AI-driven tool designed to optimize workflow efficiency and enhance productivity across various professional environments. Developed using Python, Natural Language Processing (NLP), Flask, and web technologies like HTML, CSS, and JavaScript, this assistant provides real-time assistance for a wide range of tasks with a user-friendly interface that ensures accessibility for users at all technical levels.\u003c/p\u003e\n\u003cp\u003eAt its core, the assistant leverages advanced NLP techniques to understand and respond to complex queries with high accuracy. The system integrates seamlessly with existing workflows, adding intelligent functionality without requiring significant changes to established processes. Additionally, it offers customization features that allow users to tailor the assistant’s capabilities to their specific needs, making it highly adaptable to different operational scenarios.\u003c/p\u003e","title":"Smart Assistant"},{"content":"Description As a Senior Software Developer specializing in Generative AI and Machine Learning at Cybernality GmbH, I have been deeply involved in developing a cybersecurity co-pilot designed to analyze security alerts, reduce false positives, and prioritize alarms, enabling efficient handling by less-experienced security personnel. My role involved extensive data preprocessing, where I reduced sentence lengths, cleaned, and rephrased TTPs to enhance model comprehension without losing their core meaning.\nI leveraged SecureBERT for identifying and handling domain-specific terms, improving the detection and interpretation of technical concepts in cybersecurity data. Using GPT-3.5, I rephrased complex text to ensure clarity, readability, and diversity while preserving the original intent. Additionally, I integrated preprocessed TTP data into Neo4j, allowing dynamic visualization of TTPs and SubTTPs and their relationships, making threat analysis more intuitive.\nTo enhance user guidance, I incorporated MISTRAL with the Neo4j GraphDatabase, empowering the co-pilot to guide users in identifying and navigating cybersecurity techniques and tactics effectively. Furthermore, I applied the TTPXHunter methodology to extract actionable intelligence from finished cyber threat reports, contributing to smarter and more informed decision-making processes.\nIn this role, I combined technical expertise with innovative AI methodologies, contributing to a robust, AI-powered cybersecurity solution aimed at simplifying complex threat analysis and improving overall security response efficiency.\n","permalink":"https://github.com/siri-sha-kondeti/Sirisha_Main_portfolio.git/experience/cybernality/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eAs a \u003cstrong\u003eSenior Software Developer specializing in Generative AI and Machine Learning\u003c/strong\u003e at \u003cstrong\u003eCybernality GmbH\u003c/strong\u003e, I have been deeply involved in developing a \u003cstrong\u003ecybersecurity co-pilot\u003c/strong\u003e designed to analyze security alerts, reduce false positives, and prioritize alarms, enabling efficient handling by less-experienced security personnel. My role involved extensive \u003cstrong\u003edata preprocessing\u003c/strong\u003e, where I reduced sentence lengths, cleaned, and rephrased TTPs to enhance model comprehension without losing their core meaning.\u003c/p\u003e\n\u003cp\u003eI leveraged \u003cstrong\u003eSecureBERT\u003c/strong\u003e for identifying and handling domain-specific terms, improving the detection and interpretation of technical concepts in cybersecurity data. Using \u003cstrong\u003eGPT-3.5\u003c/strong\u003e, I rephrased complex text to ensure clarity, readability, and diversity while preserving the original intent. Additionally, I integrated \u003cstrong\u003epreprocessed TTP data into Neo4j\u003c/strong\u003e, allowing dynamic visualization of \u003cstrong\u003eTTPs and SubTTPs\u003c/strong\u003e and their relationships, making threat analysis more intuitive.\u003c/p\u003e","title":"Senior Software Developer - Generative AI and Machine Learning"},{"content":"Description As a Senior Software Developer at US Software and Services Group, I played a key role in designing and deploying AI and NLP-driven solutions, focusing on enhancing operational efficiency and delivering intelligent systems across diverse domains. I worked extensively with Retrieval-Augmented Generation (RAG) methods, leveraging Dense Passage Retrieval (DPR) and T5 models to develop advanced chatbot systems capable of generating meaningful and context-aware responses.\nMy expertise included fine-tuning Large Language Models (LLMs) such as GPT, BERT, and Hugging Face Transformers for specialized tasks like text classification, summarization, and question-answering, while applying prompt engineering techniques to optimize output accuracy and relevance. I implemented similarity search using cosine similarity and vector embeddings to improve document retrieval systems, using pre-trained models to handle named entity recognition (NER) and sentiment analysis tasks effectively.\nI have hands-on experience working with structured and unstructured datasets, including text, image, graph, time series, and synthetic data, ensuring robust data preprocessing, feature engineering, and post-processing techniques like probability calibration and threshold adjustment. My contributions extended to ML model deployment using scalable frameworks such as TensorFlow and Hugging Face, focusing on real-time inference and model optimization.\nIn cloud technologies, I worked with AWS (SageMaker, Lambda, S3, EC2) and Azure (Azure ML Studio, Data Lake) to deploy and manage AI applications efficiently. Additionally, I integrated Python-React JS applications using Docker and automated workflows with CI/CD pipelines.\nI also contributed to medical image analysis projects, leveraging DICOM data formats, OpenCV, PyTorch, and AWS SageMaker for image segmentation, feature extraction, and classification tasks, ensuring compliance with medical imaging standards.\nBeyond technical implementation, I focused on cost optimization, achieving an 8% reduction in operational expenses through strategic resource allocation. I worked in Agile environments, utilizing tools like JIRA for project management and MS Tools for documentation and data processing.\nThroughout my tenure, I combined technical expertise with strategic problem-solving, delivering scalable, efficient, and impactful AI and ML solutions across a wide range of business use cases.\n","permalink":"https://github.com/siri-sha-kondeti/Sirisha_Main_portfolio.git/experience/us-software-and-services-group/","summary":"\u003ch3 id=\"description\"\u003eDescription\u003c/h3\u003e\n\u003cp\u003eAs a \u003cstrong\u003eSenior Software Developer\u003c/strong\u003e at \u003cstrong\u003eUS Software and Services Group\u003c/strong\u003e, I played a key role in designing and deploying \u003cstrong\u003eAI and NLP-driven solutions\u003c/strong\u003e, focusing on enhancing operational efficiency and delivering intelligent systems across diverse domains. I worked extensively with \u003cstrong\u003eRetrieval-Augmented Generation (RAG)\u003c/strong\u003e methods, leveraging \u003cstrong\u003eDense Passage Retrieval (DPR)\u003c/strong\u003e and \u003cstrong\u003eT5 models\u003c/strong\u003e to develop advanced chatbot systems capable of generating meaningful and context-aware responses.\u003c/p\u003e\n\u003cp\u003eMy expertise included fine-tuning \u003cstrong\u003eLarge Language Models (LLMs)\u003c/strong\u003e such as \u003cstrong\u003eGPT, BERT\u003c/strong\u003e, and \u003cstrong\u003eHugging Face Transformers\u003c/strong\u003e for specialized tasks like \u003cstrong\u003etext classification, summarization\u003c/strong\u003e, and \u003cstrong\u003equestion-answering\u003c/strong\u003e, while applying \u003cstrong\u003eprompt engineering techniques\u003c/strong\u003e to optimize output accuracy and relevance. I implemented \u003cstrong\u003esimilarity search\u003c/strong\u003e using \u003cstrong\u003ecosine similarity\u003c/strong\u003e and \u003cstrong\u003evector embeddings\u003c/strong\u003e to improve document retrieval systems, using pre-trained models to handle \u003cstrong\u003enamed entity recognition (NER)\u003c/strong\u003e and \u003cstrong\u003esentiment analysis\u003c/strong\u003e tasks effectively.\u003c/p\u003e","title":"Senior Software Developer"},{"content":"Description As a Software Developer at Talent Capital, I led the development and maintenance of a scalable e-commerce platform backend using Django, REST API, and MySQL. I collaborated with cross-functional teams to ensure seamless transactions, efficient order management, and secure data handling, utilizing SSL encryption to protect data in transit while managing and analyzing large datasets effectively.\nI worked closely with UI/UX designers to create intuitive wireframes and mockups for the dashboard interface and implemented them using HTML, CSS, JavaScript, and Bootstrap. I enhanced the dashboard with interactive features such as drill-downs, filtering, sorting, and dynamic data updates, providing users with a responsive and user-friendly experience.\nAdditionally, I designed and deployed a desktop application using Tkinter and Custom Tkinter for project management, enabling teams to collaborate effectively and track project progress in real-time.\nI also designed and implemented web applications using HTML, CSS, JavaScript, and deployed them on Apache servers, following strong Object-Oriented Programming (OOP) principles with extensive use of Python and JavaScript.\nIn backend development, I built and optimized RESTful Web Service APIs using Python and MySQL, ensuring efficient web-based data retrieval and system performance.\nThroughout my role, I emphasized building interactive, data-driven UI components, fostering team collaboration, and adhering to Agile methodologies, contributing to project efficiency and delivery in a dynamic and fast-paced development environment.\n","permalink":"https://github.com/siri-sha-kondeti/Sirisha_Main_portfolio.git/experience/talent-capital/","summary":"\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eAs a Software Developer at Talent Capital, I led the development and maintenance of a scalable e-commerce platform backend using Django, REST API, and MySQL. I collaborated with cross-functional teams to ensure seamless transactions, efficient order management, and secure data handling, utilizing SSL encryption to protect data in transit while managing and analyzing large datasets effectively.\u003c/p\u003e\n\u003cp\u003eI worked closely with UI/UX designers to create intuitive wireframes and mockups for the dashboard interface and implemented them using HTML, CSS, JavaScript, and Bootstrap. I enhanced the dashboard with interactive features such as drill-downs, filtering, sorting, and dynamic data updates, providing users with a responsive and user-friendly experience.\u003c/p\u003e","title":"Software Developer"}]